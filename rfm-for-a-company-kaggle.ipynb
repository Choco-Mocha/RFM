{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":764509,"sourceType":"datasetVersion","datasetId":397875}],"dockerImageVersionId":30698,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport warnings\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.cluster import KMeans\nfrom sklearn.metrics import silhouette_score\nfrom sklearn.cluster import AgglomerativeClustering\nfrom sklearn.preprocessing import StandardScaler\nfrom scipy.cluster.hierarchy import dendrogram, linkage\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-22T05:24:12.989908Z","iopub.execute_input":"2024-05-22T05:24:12.990352Z","iopub.status.idle":"2024-05-22T05:24:13.004722Z","shell.execute_reply.started":"2024-05-22T05:24:12.990320Z","shell.execute_reply":"2024-05-22T05:24:13.003816Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load the dataset with the specified encoding\nretail = pd.read_csv(\"/kaggle/input/online-retail-customer-clustering/OnlineRetail.csv\", encoding=\"ISO-8859-1\")\n\n# Display the first few rows of the dataset\nretail.head()\n","metadata":{"execution":{"iopub.status.busy":"2024-05-22T05:24:14.098306Z","iopub.execute_input":"2024-05-22T05:24:14.099339Z","iopub.status.idle":"2024-05-22T05:24:15.112255Z","shell.execute_reply.started":"2024-05-22T05:24:14.099303Z","shell.execute_reply":"2024-05-22T05:24:15.111012Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#dropping rows with 0 customer id\nretail = retail.dropna(subset=['CustomerID'])","metadata":{"execution":{"iopub.status.busy":"2024-05-22T05:24:16.046236Z","iopub.execute_input":"2024-05-22T05:24:16.047403Z","iopub.status.idle":"2024-05-22T05:24:16.087969Z","shell.execute_reply.started":"2024-05-22T05:24:16.047339Z","shell.execute_reply":"2024-05-22T05:24:16.086752Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"retail.describe()","metadata":{"execution":{"iopub.status.busy":"2024-05-22T05:24:17.164038Z","iopub.execute_input":"2024-05-22T05:24:17.165243Z","iopub.status.idle":"2024-05-22T05:24:17.223774Z","shell.execute_reply.started":"2024-05-22T05:24:17.165197Z","shell.execute_reply":"2024-05-22T05:24:17.222573Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#as minimum of quantity is neagative, we remove rows with <=0 quantity. \n# Display the original number of rows\nprint(\"Original number of rows:\", retail.shape[0])\n# Remove entries where Quantity is 0 or less\nretail = retail[retail['Quantity'] > 0]\n# Display the number of rows after filtering\nprint(\"Number of rows after filtering:\", retail.shape[0])\n\n# Verify that all remaining Quantity values are positive\nprint(\"All quantities are positive:\", (retail['Quantity'] > 0).all())","metadata":{"execution":{"iopub.status.busy":"2024-05-22T05:24:18.199761Z","iopub.execute_input":"2024-05-22T05:24:18.200836Z","iopub.status.idle":"2024-05-22T05:24:18.250080Z","shell.execute_reply.started":"2024-05-22T05:24:18.200799Z","shell.execute_reply":"2024-05-22T05:24:18.249073Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"retail.describe()","metadata":{"execution":{"iopub.status.busy":"2024-05-22T05:24:19.149108Z","iopub.execute_input":"2024-05-22T05:24:19.149886Z","iopub.status.idle":"2024-05-22T05:24:19.210089Z","shell.execute_reply.started":"2024-05-22T05:24:19.149851Z","shell.execute_reply":"2024-05-22T05:24:19.208935Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"retail.head(25)","metadata":{"execution":{"iopub.status.busy":"2024-05-22T05:24:20.158533Z","iopub.execute_input":"2024-05-22T05:24:20.158930Z","iopub.status.idle":"2024-05-22T05:24:20.185839Z","shell.execute_reply.started":"2024-05-22T05:24:20.158901Z","shell.execute_reply":"2024-05-22T05:24:20.184492Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We see that several invoices per each customer. each invoice itslef has many items in the order, so we will multiply each quantity with unit price.","metadata":{}},{"cell_type":"code","source":"\n# Creating a new column by multiplying 'Quantity' and 'UnitPrice'\nretail['Paid'] = retail['Quantity'] * retail['UnitPrice']\n\n# Displaying the updated DataFrame\nretail.head()\n","metadata":{"execution":{"iopub.status.busy":"2024-05-22T05:24:23.537854Z","iopub.execute_input":"2024-05-22T05:24:23.538296Z","iopub.status.idle":"2024-05-22T05:24:23.559777Z","shell.execute_reply.started":"2024-05-22T05:24:23.538259Z","shell.execute_reply":"2024-05-22T05:24:23.558612Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#we see same invoice has many items, so we will add the paid amount of each invoice\nrfm_details = retail.groupby(['CustomerID','InvoiceNo']).agg({'Paid': 'sum'}).reset_index()\nrfm_details.head()","metadata":{"execution":{"iopub.status.busy":"2024-05-22T05:24:24.585840Z","iopub.execute_input":"2024-05-22T05:24:24.586265Z","iopub.status.idle":"2024-05-22T05:24:24.683987Z","shell.execute_reply.started":"2024-05-22T05:24:24.586233Z","shell.execute_reply":"2024-05-22T05:24:24.682677Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#how much each customer paid (sum of all invoices)\nrfm_details2 = rfm_details.groupby(['CustomerID']).agg({'Paid':'sum'}).reset_index()\nrfm_details2.head()","metadata":{"execution":{"iopub.status.busy":"2024-05-22T05:24:25.513765Z","iopub.execute_input":"2024-05-22T05:24:25.514177Z","iopub.status.idle":"2024-05-22T05:24:25.530753Z","shell.execute_reply.started":"2024-05-22T05:24:25.514145Z","shell.execute_reply":"2024-05-22T05:24:25.529532Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#how many times each customer ordered (no. of unique invoices or frequency)\nfrequency_data = retail.groupby('CustomerID')['InvoiceNo'].nunique().reset_index()\nfrequency_data.columns = ['CustomerID', 'Frequency']\nrfm_details2 = pd.merge(rfm_details2, frequency_data, on='CustomerID', how='left')\nrfm_details2.head()","metadata":{"execution":{"iopub.status.busy":"2024-05-22T05:24:26.512975Z","iopub.execute_input":"2024-05-22T05:24:26.513368Z","iopub.status.idle":"2024-05-22T05:24:26.586340Z","shell.execute_reply.started":"2024-05-22T05:24:26.513339Z","shell.execute_reply":"2024-05-22T05:24:26.585067Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#making a copy of df\nrfm_details3 = rfm_details2.copy()\nrfm_details3.head()","metadata":{"execution":{"iopub.status.busy":"2024-05-22T05:24:27.498332Z","iopub.execute_input":"2024-05-22T05:24:27.499048Z","iopub.status.idle":"2024-05-22T05:24:27.518411Z","shell.execute_reply.started":"2024-05-22T05:24:27.499005Z","shell.execute_reply":"2024-05-22T05:24:27.516702Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#lets find most recent transaction and then find difference of number of days from that to the last transaction for each customer for **recency**\nlast_date = max(retail['InvoiceDate'])\nprint(last_date)","metadata":{"execution":{"iopub.status.busy":"2024-05-22T05:24:28.464215Z","iopub.execute_input":"2024-05-22T05:24:28.465661Z","iopub.status.idle":"2024-05-22T05:24:28.534918Z","shell.execute_reply.started":"2024-05-22T05:24:28.465610Z","shell.execute_reply":"2024-05-22T05:24:28.533709Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"retail_copy = retail.copy()\nretail_copy.head()","metadata":{"execution":{"iopub.status.busy":"2024-05-22T05:24:29.573285Z","iopub.execute_input":"2024-05-22T05:24:29.573708Z","iopub.status.idle":"2024-05-22T05:24:29.612248Z","shell.execute_reply.started":"2024-05-22T05:24:29.573676Z","shell.execute_reply":"2024-05-22T05:24:29.611035Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#converting datetime to standard format\nretail_copy['InvoiceDate'] = pd.to_datetime(retail_copy['InvoiceDate'], format='%d-%m-%Y %H:%M')\nretail_copy.head()","metadata":{"execution":{"iopub.status.busy":"2024-05-22T05:24:30.586082Z","iopub.execute_input":"2024-05-22T05:24:30.586734Z","iopub.status.idle":"2024-05-22T05:24:30.780600Z","shell.execute_reply.started":"2024-05-22T05:24:30.586703Z","shell.execute_reply":"2024-05-22T05:24:30.779348Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"max_date = retail_copy['InvoiceDate'].max()\n\n# Calculate the difference between the maximum date and each 'InvoiceDate'\nretail_copy['diff'] = max_date - retail_copy['InvoiceDate']\n\nretail_copy.head()","metadata":{"execution":{"iopub.status.busy":"2024-05-22T05:24:31.844702Z","iopub.execute_input":"2024-05-22T05:24:31.845070Z","iopub.status.idle":"2024-05-22T05:24:31.873915Z","shell.execute_reply.started":"2024-05-22T05:24:31.845043Z","shell.execute_reply":"2024-05-22T05:24:31.872575Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"retail_copy['diff_days'] = retail_copy['diff'].dt.days\n\n# Find the minimum 'diff_days' for each 'CustomerID'\nmin_diff_per_customer = retail_copy.groupby('CustomerID')['diff_days'].min().reset_index()\nmin_diff_per_customer.columns = ['CustomerID', 'time']\nretail_copy['diff_days'] = retail_copy['diff'].dt.days\n\n# Find the minimum 'diff_days' for each 'CustomerID'\nmin_diff_per_customer = retail_copy.groupby('CustomerID')['diff_days'].min().reset_index()\nmin_diff_per_customer.columns = ['CustomerID', 'time']\n\nretail_copy.head()","metadata":{"execution":{"iopub.status.busy":"2024-05-22T05:24:33.221947Z","iopub.execute_input":"2024-05-22T05:24:33.222369Z","iopub.status.idle":"2024-05-22T05:24:33.290293Z","shell.execute_reply.started":"2024-05-22T05:24:33.222337Z","shell.execute_reply":"2024-05-22T05:24:33.288925Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rfm_details3 = pd.merge(rfm_details3, min_diff_per_customer, on='CustomerID', how='left')\nrfm_details3.head()","metadata":{"execution":{"iopub.status.busy":"2024-05-22T05:24:34.355770Z","iopub.execute_input":"2024-05-22T05:24:34.356179Z","iopub.status.idle":"2024-05-22T05:24:34.372787Z","shell.execute_reply.started":"2024-05-22T05:24:34.356123Z","shell.execute_reply":"2024-05-22T05:24:34.371364Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"columns_to_scale = ['Paid', 'Frequency', 'time']\n\n# Initialize the MinMaxScaler\nscaler = MinMaxScaler()\n\n# Scale the specified columns\nrfm_details3[columns_to_scale] = scaler.fit_transform(rfm_details3[columns_to_scale])\n\n# Create the new DataFrame rfm_details4 with the scaled values and include the 'CustomerID' column\nrfm_details4 = rfm_details3.copy()\n\nrfm_details4.head()","metadata":{"execution":{"iopub.status.busy":"2024-05-22T05:24:35.459025Z","iopub.execute_input":"2024-05-22T05:24:35.459476Z","iopub.status.idle":"2024-05-22T05:24:35.484990Z","shell.execute_reply.started":"2024-05-22T05:24:35.459441Z","shell.execute_reply":"2024-05-22T05:24:35.484018Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# Suppress warnings\nwith warnings.catch_warnings():\n    warnings.simplefilter(\"ignore\")\n    \n    # Create the pairplot\n    sns.pairplot(rfm_details4)\n    plt.suptitle('Pairplot of rfm_details4', y=1.02)\n    plt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-05-22T05:24:36.514396Z","iopub.execute_input":"2024-05-22T05:24:36.514892Z","iopub.status.idle":"2024-05-22T05:24:46.136086Z","shell.execute_reply.started":"2024-05-22T05:24:36.514860Z","shell.execute_reply":"2024-05-22T05:24:46.134870Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# Create boxplot for 'Frequency'\nplt.figure(figsize=(8, 6))\nsns.boxplot(y=rfm_details4['Frequency'], whis=[5, 95])\nplt.title('Boxplot of Frequency (whis=[5, 95])')\nplt.ylabel('Scaled Values')\nplt.show()\n\n# Create boxplot for 'Paid' with smaller scale\nplt.figure(figsize=(8, 6))\nsns.boxplot(y=rfm_details4['Paid'], whis=[1, 99])\nplt.title('Boxplot of Paid (whis=[1, 99])')\nplt.ylabel('Scaled Values')\nplt.yticks(ticks=plt.yticks()[0], labels=[f\"{tick:.2f}\" for tick in plt.yticks()[0]])  # Change y-axis ticks to display with 2 decimal places\nplt.show()\n\n# Create boxplot for 'time' with different scale\nplt.figure(figsize=(8, 6))\nsns.boxplot(y=rfm_details4['time'], whis=[10, 90])\nplt.title('Boxplot of Time (whis=[10, 90])')\nplt.ylabel('Scaled Values')\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-05-22T05:24:48.792588Z","iopub.execute_input":"2024-05-22T05:24:48.793018Z","iopub.status.idle":"2024-05-22T05:24:49.378641Z","shell.execute_reply.started":"2024-05-22T05:24:48.792985Z","shell.execute_reply":"2024-05-22T05:24:49.377472Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"correlation_matrix = rfm_details4.corr()\n\n# Create a heatmap\nplt.figure(figsize=(10, 8))\nsns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=0.5)\nplt.title('Correlation Heatmap')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-05-22T05:24:50.512068Z","iopub.execute_input":"2024-05-22T05:24:50.513297Z","iopub.status.idle":"2024-05-22T05:24:50.855448Z","shell.execute_reply.started":"2024-05-22T05:24:50.513236Z","shell.execute_reply":"2024-05-22T05:24:50.854261Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Assuming rfm_details4 DataFrame is already defined\n# For demonstration, let's assume the DataFrame is already loaded and has the required columns\n\n# Define columns for outlier detection (excluding 'CustomerID')\nscatter_columns = ['Frequency', 'Paid', 'time']\n\n# Calculate quartiles and IQR for specified columns in rfm_details4\nQ1 = rfm_details4[scatter_columns].quantile(0.25)\nQ3 = rfm_details4[scatter_columns].quantile(0.75)\nIQR = Q3 - Q1\n\n# Define lower and upper bounds for outlier detection\nlower_bound = Q1 - 1.5 * IQR\nupper_bound = Q3 + 1.5 * IQR\n\n# Suppress warnings\nwith warnings.catch_warnings():\n    warnings.simplefilter(\"ignore\")\n    \n    # Filter the data to remove outliers, excluding 'CustomerID'\n    filtered_data = rfm_details4.copy()\n    for col in scatter_columns:\n        filtered_data = filtered_data[(filtered_data[col] >= lower_bound[col]) & (filtered_data[col] <= upper_bound[col])]\n\n    # Create scatter plots for each pair of columns with outliers removed\n    sns.pairplot(filtered_data[scatter_columns])\n    plt.suptitle('Pairplot with Outliers Removed', y=1.02)\n    plt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-05-22T05:24:52.089541Z","iopub.execute_input":"2024-05-22T05:24:52.091755Z","iopub.status.idle":"2024-05-22T05:24:55.272330Z","shell.execute_reply.started":"2024-05-22T05:24:52.091706Z","shell.execute_reply":"2024-05-22T05:24:55.271428Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"filtered_data.head(5)","metadata":{"execution":{"iopub.status.busy":"2024-05-22T05:25:39.415020Z","iopub.execute_input":"2024-05-22T05:25:39.415469Z","iopub.status.idle":"2024-05-22T05:25:39.428883Z","shell.execute_reply.started":"2024-05-22T05:25:39.415437Z","shell.execute_reply":"2024-05-22T05:25:39.427940Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create boxplot for 'Frequency'\nplt.figure(figsize=(8, 6))\nsns.boxplot(y=filtered_data['Frequency'], whis=[5, 95])\nplt.title('Boxplot of Frequency (whis=[5, 95])')\nplt.ylabel('Scaled Values')\nplt.show()\n\n# Create boxplot for 'Paid' with smaller scale\nplt.figure(figsize=(8, 6))\nsns.boxplot(y=filtered_data['Paid'], whis=[1, 99])\nplt.title('Boxplot of Paid (whis=[1, 99])')\nplt.ylabel('Scaled Values')\nplt.yticks(ticks=plt.yticks()[0], labels=[f\"{tick:.2f}\" for tick in plt.yticks()[0]])  # Change y-axis ticks to display with 2 decimal places\nplt.show()\n\n# Create boxplot for 'time' with different scale\nplt.figure(figsize=(8, 6))\nsns.boxplot(y=filtered_data['time'], whis=[10, 90])\nplt.title('Boxplot of Time (whis=[10, 90])')\nplt.ylabel('Scaled Values')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-05-22T05:25:40.521034Z","iopub.execute_input":"2024-05-22T05:25:40.521476Z","iopub.status.idle":"2024-05-22T05:25:41.273633Z","shell.execute_reply.started":"2024-05-22T05:25:40.521441Z","shell.execute_reply":"2024-05-22T05:25:41.272441Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"correlation_matrix = filtered_data.corr()\n\n# Create a heatmap\nplt.figure(figsize=(10, 8))\nsns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=0.5)\nplt.title('Correlation Heatmap')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-05-22T05:25:42.136543Z","iopub.execute_input":"2024-05-22T05:25:42.137397Z","iopub.status.idle":"2024-05-22T05:25:42.481606Z","shell.execute_reply.started":"2024-05-22T05:25:42.137349Z","shell.execute_reply":"2024-05-22T05:25:42.480391Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"filtered_data.head()","metadata":{"execution":{"iopub.status.busy":"2024-05-22T05:25:43.599325Z","iopub.execute_input":"2024-05-22T05:25:43.599973Z","iopub.status.idle":"2024-05-22T05:25:43.611742Z","shell.execute_reply.started":"2024-05-22T05:25:43.599941Z","shell.execute_reply":"2024-05-22T05:25:43.610904Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"filtered_data2 = filtered_data.copy()","metadata":{"execution":{"iopub.status.busy":"2024-05-22T05:25:55.209439Z","iopub.execute_input":"2024-05-22T05:25:55.210150Z","iopub.status.idle":"2024-05-22T05:25:55.215137Z","shell.execute_reply.started":"2024-05-22T05:25:55.210117Z","shell.execute_reply":"2024-05-22T05:25:55.214202Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"filtered_data_untouched = filtered_data.copy()","metadata":{"execution":{"iopub.status.busy":"2024-05-22T05:25:57.557759Z","iopub.execute_input":"2024-05-22T05:25:57.558176Z","iopub.status.idle":"2024-05-22T05:25:57.563696Z","shell.execute_reply.started":"2024-05-22T05:25:57.558141Z","shell.execute_reply":"2024-05-22T05:25:57.562268Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"filtered_data4 = filtered_data_untouched.copy()","metadata":{"execution":{"iopub.status.busy":"2024-05-22T05:26:00.088801Z","iopub.execute_input":"2024-05-22T05:26:00.089871Z","iopub.status.idle":"2024-05-22T05:26:00.094670Z","shell.execute_reply.started":"2024-05-22T05:26:00.089834Z","shell.execute_reply":"2024-05-22T05:26:00.093465Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#we have removed outliers, so now lets proceed with clustering.\n\ncolumns_for_elbow = ['Frequency', 'time', 'Paid']\n\n# Convert DataFrame to array\nX = filtered_data[columns_for_elbow].values\n\n# Calculate within-cluster sum of squares (WCSS) for different values of k\nwcss = []\nfor i in range(1, 11):\n    kmeans = KMeans(n_clusters=i, init='k-means++', max_iter=300, n_init=10, random_state=0)\n    kmeans.fit(X)\n    wcss.append(kmeans.inertia_)\n\n# Plot the elbow curve\nplt.figure(figsize=(8, 6))\nplt.plot(range(1, 11), wcss, marker='o', linestyle='--')\nplt.title('Elbow Method for Optimal k')\nplt.xlabel('Number of Clusters (k)')\nplt.ylabel('Within-Cluster Sum of Squares (WCSS)')\nplt.xticks(np.arange(1, 11, 1))\nplt.grid(True)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-05-22T05:26:01.720710Z","iopub.execute_input":"2024-05-22T05:26:01.721874Z","iopub.status.idle":"2024-05-22T05:26:14.380170Z","shell.execute_reply.started":"2024-05-22T05:26:01.721836Z","shell.execute_reply":"2024-05-22T05:26:14.379056Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define columns for clustering\ncluster_columns = ['Frequency', 'time', 'Paid']\n\n# Convert DataFrame to array\nX = filtered_data[cluster_columns].values\n\n# Initialize a list to store silhouette scores\nsilhouette_scores = []\n\n# Set the range of k values for silhouette analysis\nk_range = range(2, 6)\n\n# Suppress warnings\nwith warnings.catch_warnings():\n    warnings.simplefilter(\"ignore\")\n\n    # Perform silhouette analysis for each value of k\n    for k in k_range:\n        kmeans = KMeans(n_clusters=k, random_state=42)\n        cluster_labels = kmeans.fit_predict(X)\n        silhouette_avg = silhouette_score(X, cluster_labels)\n        silhouette_scores.append(silhouette_avg)\n\n# Print silhouette scores for each value of k\nfor k, silhouette_avg in zip(k_range, silhouette_scores):\n    print(f\"For n_clusters = {k}, the average silhouette score is {silhouette_avg:.4f}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-05-22T05:26:17.870902Z","iopub.execute_input":"2024-05-22T05:26:17.871344Z","iopub.status.idle":"2024-05-22T05:26:23.885803Z","shell.execute_reply.started":"2024-05-22T05:26:17.871305Z","shell.execute_reply":"2024-05-22T05:26:23.884566Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cluster_columns = ['Frequency', 'time', 'Paid']\n\n# Convert DataFrame to array\nX = filtered_data[cluster_columns].values\n\n# Initialize a list to store silhouette scores\nsilhouette_scores = []\n\n# Set the range of n_clusters values for silhouette analysis\nn_clusters_range = range(2, 6)\n\n# Perform silhouette analysis for each value of n_clusters\nfor n_clusters in n_clusters_range:\n    # Perform hierarchical clustering\n    hierarchical = AgglomerativeClustering(n_clusters=n_clusters)\n    cluster_labels = hierarchical.fit_predict(X)\n    silhouette_avg = silhouette_score(X, cluster_labels)\n    silhouette_scores.append(silhouette_avg)\n\n# Print silhouette scores for each value of n_clusters\nfor n_clusters, silhouette_avg in zip(n_clusters_range, silhouette_scores):\n    print(f\"For n_clusters = {n_clusters}, the average silhouette score is {silhouette_avg:.4f}\")","metadata":{"execution":{"iopub.status.busy":"2024-05-22T05:26:23.887769Z","iopub.execute_input":"2024-05-22T05:26:23.888819Z","iopub.status.idle":"2024-05-22T05:26:26.814784Z","shell.execute_reply.started":"2024-05-22T05:26:23.888762Z","shell.execute_reply":"2024-05-22T05:26:26.813544Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"In silhouette test of both kmeans and hierarchical clustering, and elbow test we see 2 clusters will be best.","metadata":{}},{"cell_type":"code","source":"# Define the columns for clustering\ncluster_columns = ['Frequency', 'time', 'Paid']\n\n# Convert DataFrame to array\nX = filtered_data[cluster_columns].values\n\n# Suppress warnings\nwith warnings.catch_warnings():\n    warnings.simplefilter(\"ignore\")\n    \n    # Initialize K-means with 2 clusters\n    kmeans = KMeans(n_clusters=2, random_state=42)\n    \n    # Fit K-means clustering on the data\n    kmeans.fit(X)\n    \n    # Get the cluster labels for each data point\n    cluster_labels = kmeans.labels_\n\n# Add the cluster labels to the filtered_data DataFrame\nfiltered_data['ClusterKMeans'] = cluster_labels\n\n# Print the counts of each cluster\nprint(filtered_data['ClusterKMeans'].value_counts())\n\n# Display the updated DataFrame with cluster labels\nprint(filtered_data.head())\n","metadata":{"execution":{"iopub.status.busy":"2024-05-22T05:26:31.383391Z","iopub.execute_input":"2024-05-22T05:26:31.384358Z","iopub.status.idle":"2024-05-22T05:26:32.338310Z","shell.execute_reply.started":"2024-05-22T05:26:31.384312Z","shell.execute_reply":"2024-05-22T05:26:32.337052Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# Suppress warnings\nwith warnings.catch_warnings():\n    warnings.simplefilter(\"ignore\")\n    \n    # Create pairplot with hue set to cluster assignments\n    sns.pairplot(filtered_data, hue='ClusterKMeans', palette='viridis')\n    plt.suptitle('K-means Clustering Pair Plot', y=1.02)\n    plt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-05-22T05:26:36.248575Z","iopub.execute_input":"2024-05-22T05:26:36.249004Z","iopub.status.idle":"2024-05-22T05:26:47.106760Z","shell.execute_reply.started":"2024-05-22T05:26:36.248970Z","shell.execute_reply":"2024-05-22T05:26:47.105605Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# we will take 2 clusters.","metadata":{"execution":{"iopub.status.busy":"2024-05-22T05:26:47.108629Z","iopub.execute_input":"2024-05-22T05:26:47.109723Z","iopub.status.idle":"2024-05-22T05:26:47.114531Z","shell.execute_reply.started":"2024-05-22T05:26:47.109683Z","shell.execute_reply":"2024-05-22T05:26:47.113417Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"filtered_data.head()","metadata":{"execution":{"iopub.status.busy":"2024-05-22T05:26:59.476513Z","iopub.execute_input":"2024-05-22T05:26:59.476934Z","iopub.status.idle":"2024-05-22T05:26:59.491710Z","shell.execute_reply.started":"2024-05-22T05:26:59.476900Z","shell.execute_reply":"2024-05-22T05:26:59.490324Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"filtered_data2.head()","metadata":{"execution":{"iopub.status.busy":"2024-05-22T05:27:00.736090Z","iopub.execute_input":"2024-05-22T05:27:00.736560Z","iopub.status.idle":"2024-05-22T05:27:00.750900Z","shell.execute_reply.started":"2024-05-22T05:27:00.736523Z","shell.execute_reply":"2024-05-22T05:27:00.749657Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load the data (assuming filtered_data2 is already available)\n# filtered_data2 = pd.read_csv('path_to_filtered_data2.csv')\n\n# Define the columns for clustering (excluding 'CustomerID')\ncluster_columns = ['Paid', 'Frequency', 'time']\n\n# Standardize the data (optional but recommended for clustering)\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(filtered_data2[cluster_columns])\n\n# Perform hierarchical clustering\nhierarchical = AgglomerativeClustering(n_clusters=2)\ncluster_labels = hierarchical.fit_predict(X_scaled)\n\n# Add cluster labels to the DataFrame under a new column 'cluster_Hier'\nfiltered_data2['cluster_Hier'] = cluster_labels\n\n# Visualize the dendrogram\nlinked = linkage(X_scaled, method='ward')\nplt.figure(figsize=(10, 7))\ndendrogram(linked, labels=filtered_data2['CustomerID'].values, leaf_rotation=90, leaf_font_size=10)\nplt.title('Hierarchical Clustering Dendrogram')\nplt.xlabel('CustomerID')\nplt.ylabel('Distance')\nplt.show()\n\n# Create scatter plots to visualize the clusters\nplt.figure(figsize=(8, 6))\nsns.scatterplot(data=filtered_data2, x='Frequency', y='Paid', hue='cluster_Hier', palette='viridis')\nplt.title('Hierarchical Clustering: Frequency vs Paid')\nplt.xlabel('Frequency')\nplt.ylabel('Paid')\nplt.legend(title='Cluster')\nplt.show()\n\nplt.figure(figsize=(8, 6))\nsns.scatterplot(data=filtered_data2, x='time', y='Paid', hue='cluster_Hier', palette='viridis')\nplt.title('Hierarchical Clustering: Time vs Paid')\nplt.xlabel('Time')\nplt.ylabel('Paid')\nplt.legend(title='Cluster')\nplt.show()\n\nplt.figure(figsize=(8, 6))\nsns.scatterplot(data=filtered_data2, x='time', y='Frequency', hue='cluster_Hier', palette='viridis')\nplt.title('Hierarchical Clustering: Time vs Frequency')\nplt.xlabel('Time')\nplt.ylabel('Frequency')\nplt.legend(title='Cluster')\nplt.show()\n\n# Display the updated DataFrame\nprint(filtered_data2.head())\n","metadata":{"execution":{"iopub.status.busy":"2024-05-22T05:27:01.718181Z","iopub.execute_input":"2024-05-22T05:27:01.718996Z","iopub.status.idle":"2024-05-22T05:27:52.369752Z","shell.execute_reply.started":"2024-05-22T05:27:01.718956Z","shell.execute_reply":"2024-05-22T05:27:52.368569Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"filtered_data.head()","metadata":{"execution":{"iopub.status.busy":"2024-05-22T05:28:00.828134Z","iopub.execute_input":"2024-05-22T05:28:00.829046Z","iopub.status.idle":"2024-05-22T05:28:00.843695Z","shell.execute_reply.started":"2024-05-22T05:28:00.829009Z","shell.execute_reply":"2024-05-22T05:28:00.842705Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"filtered_data2.head()","metadata":{"execution":{"iopub.status.busy":"2024-05-22T05:28:01.895980Z","iopub.execute_input":"2024-05-22T05:28:01.896391Z","iopub.status.idle":"2024-05-22T05:28:01.910804Z","shell.execute_reply.started":"2024-05-22T05:28:01.896342Z","shell.execute_reply":"2024-05-22T05:28:01.909449Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rfm_details5 = rfm_details2.copy()\nrfm_details5= pd.merge(rfm_details2, min_diff_per_customer, on='CustomerID', how='left')","metadata":{"execution":{"iopub.status.busy":"2024-05-22T05:28:03.395856Z","iopub.execute_input":"2024-05-22T05:28:03.396283Z","iopub.status.idle":"2024-05-22T05:28:03.405270Z","shell.execute_reply.started":"2024-05-22T05:28:03.396248Z","shell.execute_reply":"2024-05-22T05:28:03.403665Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rfm_details5.head()","metadata":{"execution":{"iopub.status.busy":"2024-05-22T05:28:04.673313Z","iopub.execute_input":"2024-05-22T05:28:04.673758Z","iopub.status.idle":"2024-05-22T05:28:04.686994Z","shell.execute_reply.started":"2024-05-22T05:28:04.673724Z","shell.execute_reply":"2024-05-22T05:28:04.685789Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"merged1 = pd.merge(filtered_data[['CustomerID', 'ClusterKMeans']], filtered_data2[['CustomerID', 'cluster_Hier']], on='CustomerID', how='inner')\nmerged2 = pd.merge(merged1, rfm_details5, on='CustomerID', how='inner')\n\n# Select the desired columns\nrfm_clustered = merged2[['CustomerID', 'Paid', 'Frequency', 'time', 'ClusterKMeans', 'cluster_Hier']]\n\n# Order by CustomerID\nrfm_clustered = rfm_clustered.sort_values(by='CustomerID')\n\n# Reset index (optional)\nrfm_clustered = rfm_clustered.reset_index(drop=True)\n\nrfm_clustered.head()","metadata":{"execution":{"iopub.status.busy":"2024-05-22T05:28:05.646027Z","iopub.execute_input":"2024-05-22T05:28:05.646623Z","iopub.status.idle":"2024-05-22T05:28:05.673316Z","shell.execute_reply.started":"2024-05-22T05:28:05.646584Z","shell.execute_reply":"2024-05-22T05:28:05.672191Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rfm_clustered.describe()","metadata":{"execution":{"iopub.status.busy":"2024-05-22T05:28:07.503643Z","iopub.execute_input":"2024-05-22T05:28:07.504013Z","iopub.status.idle":"2024-05-22T05:28:07.535174Z","shell.execute_reply.started":"2024-05-22T05:28:07.503984Z","shell.execute_reply":"2024-05-22T05:28:07.534081Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\nimport warnings\n\n# Suppress warnings\nwith warnings.catch_warnings():\n    warnings.simplefilter(\"ignore\")\n\n    # Create pairplot with hue set to ClusterKMeans\n    sns.pairplot(rfm_clustered, hue='ClusterKMeans')\n    plt.suptitle('Pairplot with ClusterKMeans Hue', y=1.02)\n    plt.show()\n\n    # Create pairplot with hue set to cluster_Hier\n    sns.pairplot(rfm_clustered, hue='cluster_Hier')\n    plt.suptitle('Pairplot with cluster_Hier Hue', y=1.02)\n    plt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-05-22T05:28:08.676111Z","iopub.execute_input":"2024-05-22T05:28:08.676499Z","iopub.status.idle":"2024-05-22T05:28:39.875455Z","shell.execute_reply.started":"2024-05-22T05:28:08.676462Z","shell.execute_reply":"2024-05-22T05:28:39.874364Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# Suppress warnings\nwith warnings.catch_warnings():\n    warnings.simplefilter(\"ignore\")\n\n    # Combine both cluster labels into a single string column for a single hue\n    rfm_clustered['combined_cluster'] = rfm_clustered['ClusterKMeans'].astype(str) + \"_\" + rfm_clustered['cluster_Hier'].astype(str)\n\n    # Create a pairplot with the combined clusters as hue\n    sns.pairplot(rfm_clustered, hue='combined_cluster')\n    plt.suptitle('Pairplot with Combined Clusters Hue', y=1.02)\n    plt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-05-22T05:28:46.276955Z","iopub.execute_input":"2024-05-22T05:28:46.277690Z","iopub.status.idle":"2024-05-22T05:29:10.026205Z","shell.execute_reply.started":"2024-05-22T05:28:46.277653Z","shell.execute_reply":"2024-05-22T05:29:10.024984Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rfm_clustered.head()","metadata":{"execution":{"iopub.status.busy":"2024-05-22T05:29:27.355083Z","iopub.execute_input":"2024-05-22T05:29:27.355531Z","iopub.status.idle":"2024-05-22T05:29:27.371265Z","shell.execute_reply.started":"2024-05-22T05:29:27.355498Z","shell.execute_reply":"2024-05-22T05:29:27.370078Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rfm_clustered.describe()","metadata":{"execution":{"iopub.status.busy":"2024-05-22T05:29:28.326804Z","iopub.execute_input":"2024-05-22T05:29:28.327201Z","iopub.status.idle":"2024-05-22T05:29:28.356619Z","shell.execute_reply.started":"2024-05-22T05:29:28.327171Z","shell.execute_reply":"2024-05-22T05:29:28.355471Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cluster_kmeans_0 = rfm_clustered[rfm_clustered['ClusterKMeans'] == 0]\n\n# Filter rows where ClusterKMeans is 1\ncluster_kmeans_1 = rfm_clustered[rfm_clustered['ClusterKMeans'] == 1]","metadata":{"execution":{"iopub.status.busy":"2024-05-22T05:29:29.305624Z","iopub.execute_input":"2024-05-22T05:29:29.306045Z","iopub.status.idle":"2024-05-22T05:29:29.315567Z","shell.execute_reply.started":"2024-05-22T05:29:29.306011Z","shell.execute_reply":"2024-05-22T05:29:29.314336Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cluster_kmeans_0.describe()","metadata":{"execution":{"iopub.status.busy":"2024-05-22T05:29:30.352025Z","iopub.execute_input":"2024-05-22T05:29:30.352437Z","iopub.status.idle":"2024-05-22T05:29:30.384360Z","shell.execute_reply.started":"2024-05-22T05:29:30.352403Z","shell.execute_reply":"2024-05-22T05:29:30.383107Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cluster_kmeans_1.describe()","metadata":{"execution":{"iopub.status.busy":"2024-05-22T05:29:31.146697Z","iopub.execute_input":"2024-05-22T05:29:31.147101Z","iopub.status.idle":"2024-05-22T05:29:31.180391Z","shell.execute_reply.started":"2024-05-22T05:29:31.147072Z","shell.execute_reply":"2024-05-22T05:29:31.179470Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cluster_Hier_0 = rfm_clustered[rfm_clustered['cluster_Hier'] == 0]\n\n# Filter rows where ClusterKMeans is 1\ncluster_Hier_1 = rfm_clustered[rfm_clustered['cluster_Hier'] == 1]","metadata":{"execution":{"iopub.status.busy":"2024-05-22T05:29:32.971901Z","iopub.execute_input":"2024-05-22T05:29:32.972941Z","iopub.status.idle":"2024-05-22T05:29:32.980471Z","shell.execute_reply.started":"2024-05-22T05:29:32.972905Z","shell.execute_reply":"2024-05-22T05:29:32.979092Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cluster_Hier_0.describe()","metadata":{"execution":{"iopub.status.busy":"2024-05-22T05:29:34.238205Z","iopub.execute_input":"2024-05-22T05:29:34.239401Z","iopub.status.idle":"2024-05-22T05:29:34.272322Z","shell.execute_reply.started":"2024-05-22T05:29:34.239335Z","shell.execute_reply":"2024-05-22T05:29:34.271111Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cluster_Hier_1.describe()","metadata":{"execution":{"iopub.status.busy":"2024-05-22T05:29:35.222014Z","iopub.execute_input":"2024-05-22T05:29:35.223078Z","iopub.status.idle":"2024-05-22T05:29:35.255218Z","shell.execute_reply.started":"2024-05-22T05:29:35.223034Z","shell.execute_reply":"2024-05-22T05:29:35.254047Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**K-Means Clustering**\n\n- Cluster 0:\n  This cluster consists of 2736 customers with an average payment of 1030, frequency 3.2, and time of last purchase 41.8 days.\n- Cluster 1:\n  This cluster consists of 975 customers, with an average payment of 484, frquency of 1.6 and time of last purchase 221 days.\n  \n*Cluster zero customers are of a higher value to the company as they are more recent, high spender and frequent purchasers.*\n\n**Hierarchical Clustering**\n\n- Cluster 0:\n  This cluster consists of 2974 customers with an average payment of 584, frequency 2, and time of last purchase 102 days.\n- Cluster 1:\n  This cluster consists of 737 customers, with an average payment of 2108, frquency of 6.3 and time of last purchase 33.6 days.\n  \n*Cluster one customers are of a higher value to the company as they are more recent, high spender and frequent purchasers.*\n\n**Overall Summary**\n\nKmeans clustering gives us a more general, bird eye view on valuable customers, whereas Hierarchical Clustering is more sharp and pointed outlook on customer of high importance.","metadata":{}},{"cell_type":"markdown","source":"# This document ends here, Thanks for reading!","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}